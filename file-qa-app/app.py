
import streamlit as st
from openai import OpenAI

with st.sidebar:
  openai_api_key = ''  # Placeholder for the OpenAI API key
  if openai_api_key:
      st.text("OpenAI API Key provided")  # Display a message if the API key is provided
  else:
      # Input field to capture the OpenAI API key securely as a password
      openai_api_key = st.text_input("OpenAI API Key", key="chatbot_api_key", type="password")
      "[Get an OpenAI API key](https://platform.openai.com/account/api-keys)"

# Main title of the app
st.title("üìù File Q&A with ChatGPT")

# File uploader to allow users to upload text or markdown articles
uploaded_file = st.file_uploader("Upload an article", type=("txt", "md"))

# Text input for users to ask a question related to the uploaded article
question = st.text_input(
    "Ask something about the article",
    placeholder="Can you give me a short summary?",  
    disabled=not uploaded_file,
)

# Inform the user to provide an OpenAI API key if file and question are provided but no key is entered
if uploaded_file and question and not openai_api_key:
    st.info("Please add your OpenaI API key to continue.")

# If both the file, question, and API key are provided, process the input
if uploaded_file and question and openai_api_key:
    # Read the uploaded article and decode it to a string
    article = uploaded_file.read().decode()

    # Create a prompt combining the article content and the user's question
    my_prompt = f"""Here's an article:{article}.\n\n
    \n\n\n\n{question}"""

    # Initialize the OpenAI client with the provided API key
    client = OpenAI(api_key=openai_api_key)

    # Prepare messages for the OpenAI chat model, including a system message and the user prompt
    messages = [
        {"role": "system", "content": "You are a helpful assistant."},  # System message to set the assistant's behavior
        {"role": "user", "content": my_prompt}  # User message with the article and question
    ]

    # Send the message to the GPT-3.5 model for generating a response
    response = client.chat.completions.create(
         model="gpt-3.5-turbo",  
         messages=messages  
     )

    # Display the answer generated by the model
    st.write("### Answer")
    st.write(response.choices[0].message.content)  
